{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GYIKOO/UCIMLHackathon21/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQZJ89zPlDeG"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyTGqaxwk6Ei"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBE8VlH69QXd"
      },
      "source": [
        "# Config\n",
        "save_model = Path('bertmodel.h5')\n",
        "\n",
        "seed_val = 1 # random seed for training\n",
        "\n",
        "MAX_LEN = 32\n",
        "batch_size = 64\n",
        "\n",
        "epochs = 1\n",
        "checkpoint = 2\n",
        "\n",
        "n_classes = 2 # num of labels"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FogmKgM0VrVR"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeGWsK8-WSAs"
      },
      "source": [
        "file_id = \"1sDoHyJuEGe4R3rkgWp9r0R1zHWXAYGbNjwuuckQDthg\"\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('covid_lies.csv', mimetype='text/csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkllF9eFk9KC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "bb5e288b-776e-4761-d6af-23ed9b26a101"
      },
      "source": [
        "df = pd.read_csv('covid_lies.csv')\n",
        "df = df.assign(related=[1]*len(df))\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>misconception_id</th>\n",
              "      <th>misconception</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>label</th>\n",
              "      <th>related</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Coronavirus is genetically engineered.</td>\n",
              "      <td>How the COVID-19 outbreak is changing global p...</td>\n",
              "      <td>1.233965e+18</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>Blowing conch shells destroys coronavirus pote...</td>\n",
              "      <td>Getting coronavirus and then coughing on peopl...</td>\n",
              "      <td>1.233908e+18</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57</td>\n",
              "      <td>Swans and dolphins swimming in Venice canals f...</td>\n",
              "      <td>Disturbing letter about life in COVID-19 ward ...</td>\n",
              "      <td>1.233910e+18</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>Cocaine cures coronavirus.</td>\n",
              "      <td>How to prevent corona virus?ðŸ¤” Use cowdung cake...</td>\n",
              "      <td>1.233948e+18</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>Observing janata curfew will result in the red...</td>\n",
              "      <td>This is concerning - They must self-insure for...</td>\n",
              "      <td>1.233937e+18</td>\n",
              "      <td>na</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   misconception_id  ... related\n",
              "0                 3  ...       1\n",
              "1                30  ...       1\n",
              "2                57  ...       1\n",
              "3                22  ...       1\n",
              "4                32  ...       1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dFi0fLqCNti"
      },
      "source": [
        "# Sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcG1nJPrXyED"
      },
      "source": [
        "The table of first 20 misconceptions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sd7dvQaO88VS",
        "outputId": "d74b989b-fcf3-4907-facc-984514cec204"
      },
      "source": [
        "miscon_df = df[['misconception_id','misconception']].drop_duplicates(subset='misconception_id').sort_values(by='misconception_id').reset_index(drop=True)\n",
        "mini_mdf = miscon_df[:30].reset_index(drop=True)\n",
        "mini_mdf = miscon_df\n",
        "mini_mdf"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>misconception_id</th>\n",
              "      <th>misconception</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A person can tell if they have coronavirus or ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Drinking large amounts of water will protect a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Coronavirus is genetically engineered.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dean Koontz predicted the pandemic in his 1981...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>The first person infected is a researcher name...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>58</td>\n",
              "      <td>Water polution decreased in Venice canals foll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>59</td>\n",
              "      <td>A Malabar civet was spotted walking the street...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>60</td>\n",
              "      <td>A pod of humpback whales returned to the Arabi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>61</td>\n",
              "      <td>Lions were freed to keep people off the street...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>62</td>\n",
              "      <td>Bank of England Â£20 banknotes contain a pictur...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    misconception_id                                      misconception\n",
              "0                  1  A person can tell if they have coronavirus or ...\n",
              "1                  2  Drinking large amounts of water will protect a...\n",
              "2                  3             Coronavirus is genetically engineered.\n",
              "3                  4  Dean Koontz predicted the pandemic in his 1981...\n",
              "4                  5  The first person infected is a researcher name...\n",
              "..               ...                                                ...\n",
              "57                58  Water polution decreased in Venice canals foll...\n",
              "58                59  A Malabar civet was spotted walking the street...\n",
              "59                60  A pod of humpback whales returned to the Arabi...\n",
              "60                61  Lions were freed to keep people off the street...\n",
              "61                62  Bank of England Â£20 banknotes contain a pictur...\n",
              "\n",
              "[62 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V7quvzyX5kk"
      },
      "source": [
        "The table of first 15 tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-tq1MACe90ee",
        "outputId": "3722124d-b04c-424e-a89f-cccffcf8be77"
      },
      "source": [
        "tweets_df = df[['tweet_id','tweet']].drop_duplicates(subset='tweet').sort_values(by='tweet_id')\n",
        "mini_tdf = tweets_df[:30].reset_index(drop=True)\n",
        "mini_tdf = tweets_df\n",
        "mini_tdf = mini_tdf.assign(tweet_index = [i for i in range(1,len(mini_tdf)+1)])\n",
        "mini_tdf"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3212</th>\n",
              "      <td>1.230000e+18</td>\n",
              "      <td>How long does the new coronavirus remain activ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3827</th>\n",
              "      <td>1.230000e+18</td>\n",
              "      <td>Millimetre wave technology will kill an indivi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>1.230000e+18</td>\n",
              "      <td>How do we strengthen our immune systems to fig...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5497</th>\n",
              "      <td>1.233905e+18</td>\n",
              "      <td>When it comes to coronavirus, who is the most ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1624</th>\n",
              "      <td>1.233905e+18</td>\n",
              "      <td>#Coronavirus and China's Tax Response\\n\\n@USER...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>1.233998e+18</td>\n",
              "      <td>Forget the mask. Here's how to protect yoursel...</td>\n",
              "      <td>4342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3303</th>\n",
              "      <td>1.233998e+18</td>\n",
              "      <td>Man Who Returned From Malaysia, Dies In Kerala...</td>\n",
              "      <td>4343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4058</th>\n",
              "      <td>1.233998e+18</td>\n",
              "      <td>.@miafarrow Dug up this report on exquisite ki...</td>\n",
              "      <td>4344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4385</th>\n",
              "      <td>1.233998e+18</td>\n",
              "      <td>Washington state health officials are investig...</td>\n",
              "      <td>4345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3577</th>\n",
              "      <td>1.233998e+18</td>\n",
              "      <td>MAGA hats made in China may be infected with t...</td>\n",
              "      <td>4346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4346 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          tweet_id  ... tweet_index\n",
              "3212  1.230000e+18  ...           1\n",
              "3827  1.230000e+18  ...           2\n",
              "1146  1.230000e+18  ...           3\n",
              "5497  1.233905e+18  ...           4\n",
              "1624  1.233905e+18  ...           5\n",
              "...            ...  ...         ...\n",
              "2262  1.233998e+18  ...        4342\n",
              "3303  1.233998e+18  ...        4343\n",
              "4058  1.233998e+18  ...        4344\n",
              "4385  1.233998e+18  ...        4345\n",
              "3577  1.233998e+18  ...        4346\n",
              "\n",
              "[4346 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bCJn0JKX-rg"
      },
      "source": [
        "Connect all pairs of elements in the two tables. Mark existed relationships between misconception and tweet in original dataset as 'related'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIHlyMBiXFS9"
      },
      "source": [
        "def merge_tweet_misconception(tdf, mdf, df):\n",
        "    tdf = tdf.assign(tweet_index = [i for i in range(1,len(tdf)+1)])\n",
        "    temp1 = tdf.loc[tdf.index.repeat(len(mdf))].reset_index(drop=True)\n",
        "\n",
        "    full_table = temp1.assign(misconception_id = mdf.misconception_id.values.tolist()*len(tdf),\n",
        "                  misconception = mdf.misconception.values.tolist()*len(tdf))\n",
        "\n",
        "    sample = pd.merge(full_table, df,\n",
        "         how = 'left',\n",
        "         left_on = ['tweet_id','tweet','misconception_id','misconception'],\n",
        "         right_on = ['tweet_id','tweet','misconception_id','misconception']\n",
        "        ).drop(columns='label').fillna(0)\n",
        "    sample.related = sample.related.astype('int64')\n",
        "    sample.head()\n",
        "    return sample"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ej9WB4ECc7N"
      },
      "source": [
        "# Words Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbeWLtTfCepz"
      },
      "source": [
        "def vectorize(text,MAX_LEN=MAX_LEN):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "    input_ids = []\n",
        "    for t in text:\n",
        "        # so basically encode tokenizing , mapping sentences to thier token ids after adding special tokens.\n",
        "        encoded_sent = tokenizer.encode(\n",
        "            t,  # Sentence which are encoding.\n",
        "            add_special_tokens=True,  # Adding special tokens '[CLS]' and '[SEP]'\n",
        "        )\n",
        "        input_ids.append(encoded_sent)\n",
        "\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN , truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    attention_masks = []\n",
        "    for sent in input_ids:\n",
        "        # Generating attention mask for sentences.\n",
        "        #   - when there is 0 present as token id we are going to set mask as 0.\n",
        "        #   - we are going to set mask 1 for all non-zero positive input id.\n",
        "        att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "        attention_masks.append(att_mask)\n",
        "\n",
        "    return attention_masks, input_ids"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvT6F6fCD3I3"
      },
      "source": [
        "m_text = miscon_df.misconception.values\n",
        "m_attention_mask, m_input_id = vectorize(m_text)\n",
        "\n",
        "t_text = tweets_df.tweet.values\n",
        "t_attention_mask, t_input_id = vectorize(t_text,64)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Q43zw0MTUY"
      },
      "source": [
        "def get_X_inputs_masks(sample, t_attention_mask, t_input_id, m_attention_mask, m_input_id):\n",
        "    X_inputs = []\n",
        "    X_masks = []\n",
        "\n",
        "    for i in range(0,len(sample)):\n",
        "        t_index = sample.tweet_index[i]-1\n",
        "        inputs_temp = t_input_id[t_index].tolist().copy()\n",
        "        masks_temp = t_attention_mask[t_index].copy()\n",
        "\n",
        "        m_index = sample.misconception_id[i]-1\n",
        "        inputs_temp.extend(m_input_id[m_index].tolist())\n",
        "        masks_temp.extend(m_attention_mask[m_index])\n",
        "\n",
        "        X_inputs.append(inputs_temp)\n",
        "        X_masks.append(masks_temp)\n",
        "    \n",
        "    X_inputs = np.array(X_inputs)\n",
        "    return X_inputs, X_masks"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSPwcTAcHA5d"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPI-wYKnXkMx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "train_tdf, validation_tdf = train_test_split(mini_tdf, random_state=1, test_size=0.2)\n",
        "\n",
        "# oversampling data to reduce the impact of data imbalance\n",
        "sample = merge_tweet_misconception(train_tdf, mini_mdf, df)\n",
        "oversample = sample.loc[sample[sample['related']==1].index.repeat(5)]\n",
        "train_sample = pd.concat([sample,oversample]).reset_index(drop=True)\n",
        "train_sample = shuffle(train_sample, random_state=1)\n",
        "train_labels = train_sample.related.values\n",
        "train_inputs, train_masks = get_X_inputs_masks(train_sample, t_attention_mask, t_input_id, m_attention_mask, m_input_id)\n",
        "\n",
        "validation_sample = merge_tweet_misconception(validation_tdf, miscon_df, df)\n",
        "validation_labels = validation_sample.related.values\n",
        "validation_inputs, validation_masks = get_X_inputs_masks(validation_sample, t_attention_mask, t_input_id, m_attention_mask, m_input_id)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlDOZms6mAhm",
        "outputId": "ee4b2ce4-0cb1-4d38-f749-d20e2618bddd"
      },
      "source": [
        "train_sample.groupby('related')['tweet'].count()"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "related\n",
              "0    210269\n",
              "1     31458\n",
              "Name: tweet, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPr2RNbA7151",
        "outputId": "4b4dd124-2e84-49c9-d965-615d4893c126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "validation_sample.groupby('related')['tweet'].count()"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "related\n",
              "0    52631\n",
              "1     1309\n",
              "Name: tweet, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so24p9-QZOri"
      },
      "source": [
        "# Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ7Xwu1KaM-3",
        "outputId": "ecad2088-6743-4fb5-b024-a25053d87b8e"
      },
      "source": [
        "neg, pos = np.bincount(train_sample['related'])\n",
        "total = neg + pos\n",
        "\n",
        "weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight for class 0: 0.57\n",
            "Weight for class 1: 3.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GWTty9QCP0r"
      },
      "source": [
        "# Single Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jr5bP950pRR"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t4yX8eBWjjL"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from joblib import dump, load\n",
        "\n",
        "def foresttrain(X_train, Y_train, model_name):\n",
        "    '''\n",
        "    Train the random forest classifier and save to local.\n",
        "    :param X_train:\n",
        "    :param Y_train:\n",
        "    '''\n",
        "    forest = RandomForestClassifier(n_estimators=100, oob_score=True, n_jobs=3, class_weight = class_weight) #n_job is n of CPU cores assigned\n",
        "    forest.fit(X_train, Y_train)\n",
        "    dump(forest, model_name)\n",
        "\n",
        "def forest_predict(X_val, model_name):\n",
        "    '''\n",
        "    comparing the return result with the Y_val\n",
        "    e.g.\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    accuracy_score(Y_val, forest_prediction)\n",
        "    '''\n",
        "    forest = load(model_name)\n",
        "    forest_prediction = forest.predict(X_val)\n",
        "    return forest_prediction"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwFRc1mh1tq8",
        "outputId": "09090252-72ef-4ae8-b001-2090e36663a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "foresttrain(train_inputs, train_labels,'forest.joblib')\n",
        "\n",
        "forest_pred = forest_predict(validation_inputs,'forest.joblib')\n",
        "\n",
        "binary_eval(validation_labels,forest_pred)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "overall accuracy 0.4998347823690079\n",
            "f1 0.8975601280654669\n",
            "roc_auc 0.4998347823690079\n",
            "confusion matrix [[45698  6933]\n",
            " [ 1137   172]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHE-uvGi39AN"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f_NXv2Q3_gH"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def lrtrain(X_train, Y_train, model_name):\n",
        "    lr = LogisticRegression(n_jobs=5,solver='liblinear',class_weight=class_weight)\n",
        "    lr.fit(X_train, Y_train)\n",
        "    dump(lr,model_name)\n",
        "\n",
        "def lr_predict(X_val, model_name):\n",
        "    lr= load(model_name)\n",
        "    lr_prediction = lr.predict(X_val)\n",
        "    return lr_prediction"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgtafh8q4PqD",
        "outputId": "74e17226-a140-4209-e61f-d79585b2c2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lrtrain(train_inputs, train_labels,'lr.joblib')\n",
        "\n",
        "lr_pred = lr_predict(validation_inputs,'lr.joblib')\n",
        "\n",
        "binary_eval(validation_labels,lr_pred)"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 5.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "overall accuracy 0.4951438717162787\n",
            "f1 0.6888081121903076\n",
            "roc_auc 0.4951438717162787\n",
            "confusion matrix [[29041 23590]\n",
            " [  735   574]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9A0e2qv4l2g"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMwR7GtH4C1r"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def nbtrain(X_train, Y_train, model_name):\n",
        "    '''\n",
        "    Train the Naive Bayes classifer and save to local.\n",
        "    :param X_train:\n",
        "    :param Y_train:\n",
        "    :return:\n",
        "    '''\n",
        "    nb = GaussianNB()\n",
        "    nb.fit(X_train, Y_train)\n",
        "    dump(nb, model_name)\n",
        "\n",
        "def nb_predict(X_val, model_name):\n",
        "    '''comparing the return result with the Y_val'''\n",
        "    nb = load(model_name)\n",
        "    nb_prediction = nb.predict(X_val)\n",
        "    return nb_prediction"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icf9pMss4xWQ",
        "outputId": "8f03844a-8f9e-4ce7-b83e-aac896bd2ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nbtrain(train_inputs, train_labels,'nb.joblib')\n",
        "\n",
        "nb_pred = nb_predict(validation_inputs,'nb.joblib')\n",
        "\n",
        "binary_eval(validation_labels,nb_pred)"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "overall accuracy 0.49990277089381063\n",
            "f1 0.9450825315104764\n",
            "roc_auc 0.49990277089381063\n",
            "confusion matrix [[50530  2101]\n",
            " [ 1257    52]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rudq0iC3jjX"
      },
      "source": [
        "# Voting Emsemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9fh4JNg5TyW"
      },
      "source": [
        "classfiers_pred = pd.DataFrame({'forest': forest_pred, 'nb': nb_pred, 'lr': lr_pred})"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNFgluQ-5BA3"
      },
      "source": [
        "## Train Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsHSgDfI3jAw"
      },
      "source": [
        "def train_weight(preds, label, num=3):\n",
        "    forest_pre = preds['forest'].values\n",
        "    nb_pre = preds['nb'].values\n",
        "    lr_pre = preds['lr'].values\n",
        "\n",
        "    weight = [1]*num\n",
        "    for i in range(0,len(label)):\n",
        "        update = [0]*num\n",
        "        wrong = 0\n",
        "        \n",
        "        if forest_pre[i] == label[i]:\n",
        "            update[0] = 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "\n",
        "        if nb_pre[i] == label[i]:\n",
        "            update[1] = 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "\n",
        "        if lr_pre[i] == label[i]:\n",
        "            update[2] = 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "\n",
        "        for j in range(0,num):\n",
        "            weight[j] += update[j]* wrong/num\n",
        "\n",
        "    total_weight = sum(weight)\n",
        "    for j in range(0, num):\n",
        "        weight[j] = j/total_weight\n",
        "    return weight"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5T2NL4Q3nT2",
        "outputId": "5d0c735d-95e0-4601-9f4b-e96e883bb965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "weight = train_weight(classfiers_pred,validation_labels)\n",
        "print(weight)"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 5.370665425446881e-05, 0.00010741330850893762]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtBhrF5Z52f9"
      },
      "source": [
        "## Self-defined Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgQOjfAO5tnP"
      },
      "source": [
        "def WMVEpredict(weight, preds, use_softmax=False):\n",
        "    softmax = torch.nn.Softmax()\n",
        "    result = []\n",
        "    forest_pre = preds['forest'].values\n",
        "    nb_pre = preds['nb'].values\n",
        "    lr_pre = preds['lr'].values\n",
        "\n",
        "    for i in range(0, len(forest_pre)):\n",
        "        labels = torch.FloatTensor([0,0])\n",
        "        labels[forest_pre[i]] += weight[0]\n",
        "        labels[nb_pre[i]] += weight[1]\n",
        "        labels[lr_pre[i]] += weight[2]\n",
        "\n",
        "        if use_softmax:\n",
        "            votes = softmax(labels)\n",
        "        else:\n",
        "            votes = labels\n",
        "\n",
        "        if votes[0] > votes[1]:\n",
        "            result.append(0)\n",
        "        elif votes[0] < votes[1]:\n",
        "            result.append(1)\n",
        "        else:\n",
        "            result.append(randrange(2))\n",
        "    return result"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNduGcDs6R-6",
        "outputId": "d236520c-0fea-44cb-b5f0-13ff80e1c05b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "voting_pred = WMVEpredict(weight, classfiers_pred)\n",
        "binary_eval(validation_labels,voting_pred)"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "overall accuracy 0.4951438717162787\n",
            "f1 0.6888081121903076\n",
            "roc_auc 0.4951438717162787\n",
            "confusion matrix [[29041 23590]\n",
            " [  735   574]]\n",
            "sensitivity 0.4385026737967914\n",
            "specificity 0.551785069635766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq9iR5S1_xCd"
      },
      "source": [
        "## Voting from SKLearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQpOAwzd-Oap"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=10, n_jobs=3, class_weight = class_weight)\n",
        "lr = LogisticRegression(n_jobs=5,class_weight=class_weight)\n",
        "nb = GaussianNB()\n",
        "\n",
        "estimators = [('forest',forest), ('lr',lr), ('nb',nb)]\n",
        "\n",
        "VotingCLF = VotingClassifier(estimators=estimators,\n",
        "        flatten_transform=True)"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8S8fdCO-zYf",
        "outputId": "c7897abe-e58b-4e48-d669-ab9549e7925a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "voting = VotingCLF.fit(train_inputs,train_labels)\n",
        "\n",
        "voting_pred = voting.predict(validation_inputs)\n",
        "binary_eval(validation_labels,voting_pred)"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "overall accuracy 0.4994398276807325\n",
            "f1 0.9615312603570133\n",
            "roc_auc 0.4994398276807325\n",
            "confusion matrix [[52371   260]\n",
            " [ 1304     5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBP4d8Xu3n3f"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LhhcfiJHu1W"
      },
      "source": [
        "# changing the numpy arrays into tensors for working on GPU.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "# DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# DataLoader for our validation(test) set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "class_weight = torch.FloatTensor([weight_for_0,weight_for_1])"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy1U2n12ZkD_"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDGSvcuX9fW2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def flat_confusion_matrix(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return confusion_matrix(pred_flat,labels_flat,[0,1])\n",
        "\n",
        "def plot_acc_loss(acc,loss):\n",
        "    x1 = range(0, epochs)\n",
        "    x2 = range(0, epochs)\n",
        "    y1 = acc\n",
        "    y2 = loss\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(x1, y1, 'o-')\n",
        "    plt.title('Test accuracy vs. epoches')\n",
        "    plt.ylabel('Test accuracy')\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(x2, y2, '.-')\n",
        "    plt.xlabel('Test loss vs. epoches')\n",
        "    plt.ylabel('Test loss')\n",
        "    plt.show()"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jstl6HRLZnIw"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCpFwfAX88fj"
      },
      "source": [
        "def bertpretrain(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    if save_model.exists():\n",
        "        model = torch.load(save_model)\n",
        "    else:\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-uncased\",\n",
        "            num_labels=n_classes,\n",
        "            output_attentions=False,\n",
        "            output_hidden_states=False\n",
        "            )\n",
        "\n",
        "    # Running the model on GPU.\n",
        "    model.cuda()\n",
        "\n",
        "    # Running on GPU if available, otherwise on CPU\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr = 2e-5,\n",
        "                      eps = 1e-8\n",
        "                      )\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,  # Default value in run_glue.py\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    # Set the seed value all over the place to make this reproducible.\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # Store the average loss after each epoch so we can plot them.\n",
        "    loss_values = []\n",
        "\n",
        "    val_accuracy = []\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_loss = 0\n",
        "\n",
        "        model.train() # switch to training mode\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader.\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids\n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Clear any previously calculated gradients before performing a backward pass.\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            outputs = model(b_input_ids,\n",
        "                     token_type_ids=None,\n",
        "                     attention_mask=b_input_mask,\n",
        "                     labels=b_labels)\n",
        "\n",
        "            # Pull the loss value out of the tuple.\n",
        "            #loss = outputs[0]\n",
        "            ce = torch.nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
        "            loss = ce(outputs[1],b_labels)\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end.\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # Store the loss value for plotting the learning curve.\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "\n",
        "        # ========================================\n",
        "        #         Validation\n",
        "        # ========================================\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time() # Validation start time\n",
        "\n",
        "        # Put the model in evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        val_conf_matrix = [np.array([0,0]),np.array([0,0])]\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            # Telling the model not to compute or store gradients, saving memory and\n",
        "            # speeding up validation\n",
        "            with torch.no_grad():\n",
        "                outputs = model(b_input_ids,\n",
        "                         token_type_ids=None,\n",
        "                         attention_mask=b_input_mask)\n",
        "\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            logits = outputs[0]\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "            tmp_confusion_matrix = flat_confusion_matrix(logits,label_ids)\n",
        "\n",
        "            # Accumulate the total accuracy.\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            val_conf_matrix += tmp_confusion_matrix\n",
        "\n",
        "            # Track the number of batches\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        val_accuracy.append(eval_accuracy / nb_eval_steps)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy / nb_eval_steps))\n",
        "        print(\"  Confusion matrix:\", val_conf_matrix)\n",
        "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "        if epoch % checkpoint == 0:\n",
        "          torch.save(model,save_model)\n",
        " \n",
        "\n",
        "    print(\"Saving model...\")\n",
        "    torch.save(model, save_model)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    return val_accuracy, loss_values, val_conf_matrix\n"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDda8wH49fLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84edd896-fe38-4fb9-e485-a38a9c99d124"
      },
      "source": [
        "val_accuracy, loss_values, val_conf_matrix = bertpretrain(train_dataloader, validation_dataloader)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  4,187.    Elapsed: 0:00:23.\n",
            "  Batch    80  of  4,187.    Elapsed: 0:00:45.\n",
            "  Batch   120  of  4,187.    Elapsed: 0:01:08.\n",
            "  Batch   160  of  4,187.    Elapsed: 0:01:30.\n",
            "  Batch   200  of  4,187.    Elapsed: 0:01:52.\n",
            "  Batch   240  of  4,187.    Elapsed: 0:02:15.\n",
            "  Batch   280  of  4,187.    Elapsed: 0:02:37.\n",
            "  Batch   320  of  4,187.    Elapsed: 0:03:00.\n",
            "  Batch   360  of  4,187.    Elapsed: 0:03:22.\n",
            "  Batch   400  of  4,187.    Elapsed: 0:03:45.\n",
            "  Batch   440  of  4,187.    Elapsed: 0:04:07.\n",
            "  Batch   480  of  4,187.    Elapsed: 0:04:30.\n",
            "  Batch   520  of  4,187.    Elapsed: 0:04:52.\n",
            "  Batch   560  of  4,187.    Elapsed: 0:05:15.\n",
            "  Batch   600  of  4,187.    Elapsed: 0:05:37.\n",
            "  Batch   640  of  4,187.    Elapsed: 0:05:59.\n",
            "  Batch   680  of  4,187.    Elapsed: 0:06:22.\n",
            "  Batch   720  of  4,187.    Elapsed: 0:06:44.\n",
            "  Batch   760  of  4,187.    Elapsed: 0:07:07.\n",
            "  Batch   800  of  4,187.    Elapsed: 0:07:29.\n",
            "  Batch   840  of  4,187.    Elapsed: 0:07:52.\n",
            "  Batch   880  of  4,187.    Elapsed: 0:08:14.\n",
            "  Batch   920  of  4,187.    Elapsed: 0:08:36.\n",
            "  Batch   960  of  4,187.    Elapsed: 0:08:59.\n",
            "  Batch 1,000  of  4,187.    Elapsed: 0:09:21.\n",
            "  Batch 1,040  of  4,187.    Elapsed: 0:09:44.\n",
            "  Batch 1,080  of  4,187.    Elapsed: 0:10:06.\n",
            "  Batch 1,120  of  4,187.    Elapsed: 0:10:29.\n",
            "  Batch 1,160  of  4,187.    Elapsed: 0:10:51.\n",
            "  Batch 1,200  of  4,187.    Elapsed: 0:11:13.\n",
            "  Batch 1,240  of  4,187.    Elapsed: 0:11:36.\n",
            "  Batch 1,280  of  4,187.    Elapsed: 0:11:58.\n",
            "  Batch 1,320  of  4,187.    Elapsed: 0:12:21.\n",
            "  Batch 1,360  of  4,187.    Elapsed: 0:12:43.\n",
            "  Batch 1,400  of  4,187.    Elapsed: 0:13:06.\n",
            "  Batch 1,440  of  4,187.    Elapsed: 0:13:28.\n",
            "  Batch 1,480  of  4,187.    Elapsed: 0:13:50.\n",
            "  Batch 1,520  of  4,187.    Elapsed: 0:14:13.\n",
            "  Batch 1,560  of  4,187.    Elapsed: 0:14:35.\n",
            "  Batch 1,600  of  4,187.    Elapsed: 0:14:58.\n",
            "  Batch 1,640  of  4,187.    Elapsed: 0:15:20.\n",
            "  Batch 1,680  of  4,187.    Elapsed: 0:15:42.\n",
            "  Batch 1,720  of  4,187.    Elapsed: 0:16:05.\n",
            "  Batch 1,760  of  4,187.    Elapsed: 0:16:27.\n",
            "  Batch 1,800  of  4,187.    Elapsed: 0:16:50.\n",
            "  Batch 1,840  of  4,187.    Elapsed: 0:17:12.\n",
            "  Batch 1,880  of  4,187.    Elapsed: 0:17:35.\n",
            "  Batch 1,920  of  4,187.    Elapsed: 0:17:57.\n",
            "  Batch 1,960  of  4,187.    Elapsed: 0:18:19.\n",
            "  Batch 2,000  of  4,187.    Elapsed: 0:18:42.\n",
            "  Batch 2,040  of  4,187.    Elapsed: 0:19:04.\n",
            "  Batch 2,080  of  4,187.    Elapsed: 0:19:27.\n",
            "  Batch 2,120  of  4,187.    Elapsed: 0:19:49.\n",
            "  Batch 2,160  of  4,187.    Elapsed: 0:20:11.\n",
            "  Batch 2,200  of  4,187.    Elapsed: 0:20:34.\n",
            "  Batch 2,240  of  4,187.    Elapsed: 0:20:56.\n",
            "  Batch 2,280  of  4,187.    Elapsed: 0:21:19.\n",
            "  Batch 2,320  of  4,187.    Elapsed: 0:21:41.\n",
            "  Batch 2,360  of  4,187.    Elapsed: 0:22:03.\n",
            "  Batch 2,400  of  4,187.    Elapsed: 0:22:26.\n",
            "  Batch 2,440  of  4,187.    Elapsed: 0:22:48.\n",
            "  Batch 2,480  of  4,187.    Elapsed: 0:23:11.\n",
            "  Batch 2,520  of  4,187.    Elapsed: 0:23:33.\n",
            "  Batch 2,560  of  4,187.    Elapsed: 0:23:56.\n",
            "  Batch 2,600  of  4,187.    Elapsed: 0:24:18.\n",
            "  Batch 2,640  of  4,187.    Elapsed: 0:24:40.\n",
            "  Batch 2,680  of  4,187.    Elapsed: 0:25:03.\n",
            "  Batch 2,720  of  4,187.    Elapsed: 0:25:25.\n",
            "  Batch 2,760  of  4,187.    Elapsed: 0:25:48.\n",
            "  Batch 2,800  of  4,187.    Elapsed: 0:26:10.\n",
            "  Batch 2,840  of  4,187.    Elapsed: 0:26:32.\n",
            "  Batch 2,880  of  4,187.    Elapsed: 0:26:55.\n",
            "  Batch 2,920  of  4,187.    Elapsed: 0:27:17.\n",
            "  Batch 2,960  of  4,187.    Elapsed: 0:27:40.\n",
            "  Batch 3,000  of  4,187.    Elapsed: 0:28:02.\n",
            "  Batch 3,040  of  4,187.    Elapsed: 0:28:24.\n",
            "  Batch 3,080  of  4,187.    Elapsed: 0:28:47.\n",
            "  Batch 3,120  of  4,187.    Elapsed: 0:29:09.\n",
            "  Batch 3,160  of  4,187.    Elapsed: 0:29:32.\n",
            "  Batch 3,200  of  4,187.    Elapsed: 0:29:54.\n",
            "  Batch 3,240  of  4,187.    Elapsed: 0:30:17.\n",
            "  Batch 3,280  of  4,187.    Elapsed: 0:30:39.\n",
            "  Batch 3,320  of  4,187.    Elapsed: 0:31:01.\n",
            "  Batch 3,360  of  4,187.    Elapsed: 0:31:24.\n",
            "  Batch 3,400  of  4,187.    Elapsed: 0:31:46.\n",
            "  Batch 3,440  of  4,187.    Elapsed: 0:32:09.\n",
            "  Batch 3,480  of  4,187.    Elapsed: 0:32:31.\n",
            "  Batch 3,520  of  4,187.    Elapsed: 0:32:53.\n",
            "  Batch 3,560  of  4,187.    Elapsed: 0:33:16.\n",
            "  Batch 3,600  of  4,187.    Elapsed: 0:33:38.\n",
            "  Batch 3,640  of  4,187.    Elapsed: 0:34:01.\n",
            "  Batch 3,680  of  4,187.    Elapsed: 0:34:23.\n",
            "  Batch 3,720  of  4,187.    Elapsed: 0:34:45.\n",
            "  Batch 3,760  of  4,187.    Elapsed: 0:35:08.\n",
            "  Batch 3,800  of  4,187.    Elapsed: 0:35:30.\n",
            "  Batch 3,840  of  4,187.    Elapsed: 0:35:53.\n",
            "  Batch 3,880  of  4,187.    Elapsed: 0:36:15.\n",
            "  Batch 3,920  of  4,187.    Elapsed: 0:36:38.\n",
            "  Batch 3,960  of  4,187.    Elapsed: 0:37:00.\n",
            "  Batch 4,000  of  4,187.    Elapsed: 0:37:23.\n",
            "  Batch 4,040  of  4,187.    Elapsed: 0:37:45.\n",
            "  Batch 4,080  of  4,187.    Elapsed: 0:38:07.\n",
            "  Batch 4,120  of  4,187.    Elapsed: 0:38:30.\n",
            "  Batch 4,160  of  4,187.    Elapsed: 0:38:52.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:39:07\n",
            "\n",
            "Running Validation on Training Data...\n",
            "  Accuracy: 0.77\n",
            "  Confusion matrix: [[203123  55643]\n",
            " [  7146   2030]]\n",
            "  Validation took: 0:12:45\n",
            "\n",
            "Running Validation on Test Data...\n",
            "  Accuracy: 0.94\n",
            "  Confusion matrix: [[50859  1266]\n",
            " [ 1772    43]]\n",
            "  Validation took: 0:02:34\n",
            "Saving model...\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8it-uzGT-yj",
        "outputId": "8d32fda1-77cd-4c51-e8b8-7b2ccd72c06b"
      },
      "source": [
        "# oversampling 5\n",
        "train_conf_matrix "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[614,  76],\n",
              "       [ 85,  50]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dwVQjh9UB13",
        "outputId": "74f61e08-1286-43a1-9e65-e7f5a3d4f4ed"
      },
      "source": [
        "# oversampling 5\n",
        "val_conf_matrix"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[272,   6],\n",
              "       [ 93,   1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6E22JXRLTIaN",
        "outputId": "8312ddeb-e20d-43b7-bb49-dda2e44fd997"
      },
      "source": [
        "plot_acc_loss(val_accuracy,loss_values)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oth3ltJUTTN"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_kYrw94Uf79"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, balanced_accuracy_score, roc_auc_score\n",
        "\n",
        "def binary_eval(label, prediction):\n",
        "    print('overall accuracy', balanced_accuracy_score(label, prediction))\n",
        "    print('f1',f1_score(label, prediction, average='weighted'))\n",
        "    print('roc_auc', roc_auc_score(label, prediction, average='weighted'))\n",
        "    c_matrix = confusion_matrix(label, prediction)\n",
        "    print('confusion matrix', c_matrix)\n",
        "    sensitivity = c_matrix[1][1]/(c_matrix[1][1]+c_matrix[1][0])\n",
        "    specificity = c_matrix[0][0]/(c_matrix[0][0]+c_matrix[0][1])\n",
        "    print('sensitivity',sensitivity)\n",
        "    print('specificity',specificity)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fToY73Tz9fOD"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "def bertpredict(model,inputs,masks):\n",
        "    bert_pred = model(inputs.to(device),\n",
        "              token_type_ids=None,\n",
        "              attention_mask=masks.to(device))[0].detach().cpu().numpy()\n",
        "    bertpred_class = np.argmax(bert_pred,axis=1).flatten()\n",
        "    return bertpred_class"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foISRd-xTTGh"
      },
      "source": [
        "bert = torch.load(save_model)\n",
        "\n",
        "result = bertpredict(bert, validation_inputs, validation_masks)\n",
        "binary_eval(validation_labels,result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}